from NN.KerasOut import MultiLayerPerceptron

xs = [
  [2.0, 3.0, -1.0],
  [3.0, -1.0, 0.5],
  [0.5, 1.0, 1.0],
  [1.0, 1.0, -1.0],
  [1.0, 2.0, -0.4],
  [0.2, -0.5, 1.2],
  [2.0, 3.0, -1.0],
  [3.0, -1.0, 0.5],
  [0.5, 1.0, 1.0],
  [1.0, 1.0, -1.0],
  [1.0, 2.0, -0.4],
  [0.2, -0.5, 1.2],
  [2.0, 3.0, -1.0],
  [3.0, -1.0, 0.5],
  [0.5, 1.0, 1.0],
  [1.0, 1.0, -1.0],
  [1.0, 2.0, -0.4],
  [0.2, -0.5, 1.2],
  [2.0, 3.0, -1.0],
  [3.0, -1.0, 0.5],
  [0.5, 1.0, 1.0],
  [1.0, 1.0, -1.0],
  [1.0, 2.0, -0.4],
  [0.2, -0.5, 1.2],
]
ys = [1.0, 0.0, 0.0, 1.0, 1.0, 0.0,1.0, 0.0, 0.0, 1.0, 1.0, 0.0,1.0, 0.0, 0.0, 1.0, 1.0, 0.0,1.0, 0.0, 0.0, 1.0, 1.0, 0.0] 

xs = [
  [2.0, 3.0, -1.0],
  [3.0, -1.0, 0.5],
  [0.5, 1.0, 1.0],
  [1.0, 1.0, -1.0],
  [1.0, 2.0, -0.4],
  [0.2, -0.5, 1.2]
]
ys = [ 
  [0.0, 1.0, 0.0],
  [1.0, 0.0, 0.0],
  [0.0, 0.0, 1.0],
  [0.0, 1.0, 0.0],
  [0.0, 0.0, 1.0],
  [1.0, 0.0, 0.0]
]

# ys = [1.0, 0.0, 0.0, 1.0, 1.0, 0.0] 

model = MultiLayerPerceptron(3, [32, 16, 8, 3], ['sigmoid', 'sigmoid', 'sigmoid', 'soft_max'])
model.fit(xs, ys, 'CE')
loss = model.optimize(1000)
# for layer in model.layers:
#   for neuron in layer.neurons:
#     print(f"Layer: {layer}\nNeuron: {neuron.parameters()}\n")


# fix the cross entropy and make it like the activation in the tensor class


# print(model.prediction())
